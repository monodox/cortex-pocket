{
  "supported_models": [
    {
      "name": "Llama 3.2 3B",
      "size": "2.0GB",
      "url": "https://huggingface.co/meta-llama/Llama-3.2-3B-Instruct-GGUF",
      "description": "Meta's latest 3B parameter model, optimized for mobile",
      "license": "Llama 3.2 Community License",
      "quantizations": ["Q3", "Q4", "Q6", "Q8"],
      "recommended_for": ["High-end phones", "General conversation", "Code assistance"],
      "memory_requirements": {
        "Q3": "1.5GB",
        "Q4": "2.0GB",
        "Q6": "2.8GB",
        "Q8": "3.5GB"
      }
    },
    {
      "name": "Phi-3.5 Mini",
      "size": "2.2GB",
      "url": "https://huggingface.co/microsoft/Phi-3.5-mini-instruct-gguf",
      "description": "Microsoft's efficient 3.8B parameter model",
      "license": "MIT License",
      "quantizations": ["Q3", "Q4", "Q6", "Q8"],
      "recommended_for": ["Mid-range devices", "Balanced performance", "Technical tasks"],
      "memory_requirements": {
        "Q3": "1.8GB",
        "Q4": "2.2GB",
        "Q6": "3.0GB",
        "Q8": "3.8GB"
      }
    },
    {
      "name": "Qwen2.5 3B",
      "size": "1.9GB",
      "url": "https://huggingface.co/Qwen/Qwen2.5-3B-Instruct-GGUF",
      "description": "Alibaba's multilingual 3B model with strong coding abilities",
      "license": "Apache 2.0",
      "quantizations": ["Q3", "Q4", "Q6", "Q8"],
      "recommended_for": ["Multilingual support", "Code generation", "Technical writing"],
      "memory_requirements": {
        "Q3": "1.4GB",
        "Q4": "1.9GB",
        "Q6": "2.6GB",
        "Q8": "3.2GB"
      }
    },
    {
      "name": "Gemma 2 2B",
      "size": "1.6GB",
      "url": "https://huggingface.co/google/gemma-2-2b-it-GGUF",
      "description": "Google's lightweight 2B parameter model",
      "license": "Gemma Terms of Use",
      "quantizations": ["Q3", "Q4", "Q6", "Q8"],
      "recommended_for": ["Low-end devices", "Battery efficiency", "Quick responses"],
      "memory_requirements": {
        "Q3": "1.0GB",
        "Q4": "1.6GB",
        "Q6": "2.2GB",
        "Q8": "2.8GB"
      }
    },
    {
      "name": "CodeLlama 7B",
      "size": "3.8GB",
      "url": "https://huggingface.co/codellama/CodeLlama-7b-Instruct-hf",
      "description": "Meta's specialized code generation model",
      "license": "Llama 2 Community License",
      "quantizations": ["Q3", "Q4", "Q6", "Q8"],
      "recommended_for": ["Code generation", "Programming assistance", "High-end devices"],
      "memory_requirements": {
        "Q3": "2.8GB",
        "Q4": "3.8GB",
        "Q6": "5.2GB",
        "Q8": "6.8GB"
      }
    }
  ],
  "remote_models": {
    "gemini": [
      {
        "id": "gemini-2.5-flash",
        "name": "Gemini 2.5 Flash",
        "description": "Fast and efficient model for general tasks",
        "default": true
      },
      {
        "id": "gemini-2.5-pro",
        "name": "Gemini 2.5 Pro",
        "description": "Advanced model for complex reasoning"
      },
      {
        "id": "gemini-2.5-flash-lite",
        "name": "Gemini 2.5 Flash Lite",
        "description": "Lightweight version for quick responses"
      },
      {
        "id": "gemini-3-pro-preview",
        "name": "Gemini 3 Pro Preview",
        "description": "Latest experimental model"
      }
    ],
    "openai": [
      {
        "id": "gpt-3.5-turbo",
        "name": "GPT-3.5 Turbo",
        "description": "Fast and cost-effective model"
      },
      {
        "id": "gpt-4",
        "name": "GPT-4",
        "description": "Advanced reasoning and analysis"
      },
      {
        "id": "gpt-4-turbo",
        "name": "GPT-4 Turbo",
        "description": "Optimized GPT-4 with better performance"
      }
    ]
  },
  "device_recommendations": {
    "high_end": {
      "ram": "8GB+",
      "storage": "4GB+ free",
      "recommended_models": ["Llama 3.2 3B Q4", "CodeLlama 7B Q4", "Qwen2.5 3B Q6"]
    },
    "mid_range": {
      "ram": "4-8GB",
      "storage": "2GB+ free",
      "recommended_models": ["Phi-3.5 Mini Q4", "Qwen2.5 3B Q4", "Llama 3.2 3B Q3"]
    },
    "low_end": {
      "ram": "2-4GB",
      "storage": "1GB+ free",
      "recommended_models": ["Gemma 2 2B Q4", "Phi-3.5 Mini Q3", "Qwen2.5 3B Q3"]
    }
  }
}